{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd440a7a",
   "metadata": {},
   "source": [
    "# Predicting Customer Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54711300",
   "metadata": {},
   "source": [
    "### Yu chien (Calvin) Ma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bacdbe8",
   "metadata": {},
   "source": [
    "## Installing Dependencies and Initializing Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ea53339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\calvi\\\\anaconda3\\\\lib\\\\site-packages\\\\pyspark'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1afe83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".appName('spark') \\\n",
    ".master('local[*]') \\\n",
    ".config('spark.sql.execution.arrow.pyspark.enabled', True) \\\n",
    ".config('spark.sql.session.timeZone', 'UTC') \\\n",
    ".config('spark.driver.memory','16G') \\\n",
    ".config('spark.ui.showConsoleProgress', True) \\\n",
    ".config('spark.sql.repl.eagerEval.enabled', True) \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09421f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloning repository\n",
    "# !git clone https://github.com/calvinma888/PySparkML_CustomerChurn.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e6cee1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of dataset\n",
    "path = r\"C:\\Users\\calvi\\Documents\\Portfolio Projects\\Predicting Customer Churn\\Churn_Modelling.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "423dc247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a spark dataframe\n",
    "df = spark.read.csv(path, header=True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af1b3e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
      "|RowNumber|CustomerId| Surname|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
      "|        1|  15634602|Hargrave|        619|   France|Female| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|\n",
      "|        2|  15647311|    Hill|        608|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|\n",
      "|        3|  15619304|    Onio|        502|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|\n",
      "|        4|  15701354|    Boni|        699|   France|Female| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|\n",
      "|        5|  15737888|Mitchell|        850|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|\n",
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3fa14747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n"
     ]
    }
   ],
   "source": [
    "#get the no.of rows & columns\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dea1823e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RowNumber: integer (nullable = true)\n",
      " |-- CustomerId: integer (nullable = true)\n",
      " |-- Surname: string (nullable = true)\n",
      " |-- CreditScore: integer (nullable = true)\n",
      " |-- Geography: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tenure: integer (nullable = true)\n",
      " |-- Balance: double (nullable = true)\n",
      " |-- NumOfProducts: integer (nullable = true)\n",
      " |-- HasCrCard: integer (nullable = true)\n",
      " |-- IsActiveMember: integer (nullable = true)\n",
      " |-- EstimatedSalary: double (nullable = true)\n",
      " |-- Exited: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print schema \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b3af917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>RowNumber</th><th>CustomerId</th><th>Surname</th><th>CreditScore</th><th>Geography</th><th>Gender</th><th>Age</th><th>Tenure</th><th>Balance</th><th>NumOfProducts</th><th>HasCrCard</th><th>IsActiveMember</th><th>EstimatedSalary</th><th>Exited</th></tr>\n",
       "<tr><td>count</td><td>10000</td><td>10000</td><td>10000</td><td>10000</td><td>10000</td><td>10000</td><td>10000</td><td>10000</td><td>10000</td><td>10000</td><td>10000</td><td>10000</td><td>10000</td><td>10000</td></tr>\n",
       "<tr><td>mean</td><td>5000.5</td><td>1.56909405694E7</td><td>null</td><td>650.5288</td><td>null</td><td>null</td><td>38.9218</td><td>5.0128</td><td>76485.88928799961</td><td>1.5302</td><td>0.7055</td><td>0.5151</td><td>100090.2398809998</td><td>0.2037</td></tr>\n",
       "<tr><td>stddev</td><td>2886.8956799071675</td><td>71936.18612274907</td><td>null</td><td>96.65329873613035</td><td>null</td><td>null</td><td>10.487806451704587</td><td>2.8921743770496837</td><td>62397.40520238599</td><td>0.5816543579989917</td><td>0.45584046447513327</td><td>0.49979692845891815</td><td>57510.49281769821</td><td>0.40276858399486065</td></tr>\n",
       "<tr><td>min</td><td>1</td><td>15565701</td><td>Abazu</td><td>350</td><td>France</td><td>Female</td><td>18</td><td>0</td><td>0.0</td><td>1</td><td>0</td><td>0</td><td>11.58</td><td>0</td></tr>\n",
       "<tr><td>max</td><td>10000</td><td>15815690</td><td>Zuyeva</td><td>850</td><td>Spain</td><td>Male</td><td>92</td><td>10</td><td>250898.09</td><td>4</td><td>1</td><td>1</td><td>199992.48</td><td>1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------------+-----------------+-------+-----------------+---------+------+------------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+-------------------+\n",
       "|summary|         RowNumber|       CustomerId|Surname|      CreditScore|Geography|Gender|               Age|            Tenure|          Balance|     NumOfProducts|          HasCrCard|     IsActiveMember|  EstimatedSalary|             Exited|\n",
       "+-------+------------------+-----------------+-------+-----------------+---------+------+------------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+-------------------+\n",
       "|  count|             10000|            10000|  10000|            10000|    10000| 10000|             10000|             10000|            10000|             10000|              10000|              10000|            10000|              10000|\n",
       "|   mean|            5000.5|  1.56909405694E7|   null|         650.5288|     null|  null|           38.9218|            5.0128|76485.88928799961|            1.5302|             0.7055|             0.5151|100090.2398809998|             0.2037|\n",
       "| stddev|2886.8956799071675|71936.18612274907|   null|96.65329873613035|     null|  null|10.487806451704587|2.8921743770496837|62397.40520238599|0.5816543579989917|0.45584046447513327|0.49979692845891815|57510.49281769821|0.40276858399486065|\n",
       "|    min|                 1|         15565701|  Abazu|              350|   France|Female|                18|                 0|              0.0|                 1|                  0|                  0|            11.58|                  0|\n",
       "|    max|             10000|         15815690| Zuyeva|              850|    Spain|  Male|                92|                10|        250898.09|                 4|                  1|                  1|        199992.48|                  1|\n",
       "+-------+------------------+-----------------+-------+-----------------+---------+------+------------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+-------------------+"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf75af6",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee22a38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RowNumber', 'int'),\n",
       " ('CustomerId', 'int'),\n",
       " ('Surname', 'string'),\n",
       " ('CreditScore', 'int'),\n",
       " ('Geography', 'string'),\n",
       " ('Gender', 'string'),\n",
       " ('Age', 'int'),\n",
       " ('Tenure', 'int'),\n",
       " ('Balance', 'double'),\n",
       " ('NumOfProducts', 'int'),\n",
       " ('HasCrCard', 'int'),\n",
       " ('IsActiveMember', 'int'),\n",
       " ('EstimatedSalary', 'double'),\n",
       " ('Exited', 'int')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the datatype of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c9f65771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating categorical and numerical columns\n",
    "categoricalColumns = [item[0] for item in df.dtypes if item[1].startswith('string') ]\n",
    "numericalColumns = list(set(df.columns)-set(categoricalColumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "12188c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Surname', 'Geography', 'Gender']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricalColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77cc071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RowNumber',\n",
       " 'CustomerId',\n",
       " 'IsActiveMember',\n",
       " 'Tenure',\n",
       " 'HasCrCard',\n",
       " 'CreditScore',\n",
       " 'Age',\n",
       " 'Balance',\n",
       " 'EstimatedSalary',\n",
       " 'NumOfProducts',\n",
       " 'Exited']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericalColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83d96feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical columns into indices\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "stages = []\n",
    "\n",
    "# convert sting column to index column    \n",
    "indexer = StringIndexer(inputCols=categoricalColumns, outputCols=[x + \"Index\" for x in categoricalColumns]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "202e3c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode categorical columns to numerical vector columns\n",
    "encoder = OneHotEncoder(inputCols=indexer.getOutputCols(), \\\n",
    "                        outputCols=[x + \"_OHE\" for x in categoricalColumns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b3f72dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform numerical columns to a single vector column\n",
    "# We don't want the last item (\"Exited\") because that is the target\n",
    "num_assembler = VectorAssembler(inputCols=numericalColumns[:-1], outputCol='num_features',\\\n",
    "                                handleInvalid='keep')\n",
    "\n",
    "# apply scaler Rescale each feature individually to a common range [min, max] linearly using column summary statistics, \n",
    "# which is also known as min-max normalization or rescaling.\n",
    "scaler = MinMaxScaler(inputCol='num_features', outputCol='scaled_num_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0ca3a18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Surname_OHE', 'Geography_OHE', 'Gender_OHE', 'scaled_num_features']\n"
     ]
    }
   ],
   "source": [
    "numericalScaled = [\"scaled_num_features\"]\n",
    "\n",
    "assemblerInputs = [c + \"_OHE\" for c in categoricalColumns] + numericalScaled\n",
    "print(assemblerInputs)\n",
    "\n",
    "# transform all create vector columns into one vector column\n",
    "assembler = VectorAssembler(inputCols= assemblerInputs, \\\n",
    "                            outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "764286e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline with above steps\n",
    "data_pipeline = Pipeline(stages=[indexer,encoder, num_assembler, scaler, assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a1397a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit pipeline and transform dataframe\n",
    "dataset = data_pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d0fc92a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+------------+--------------+-----------+-------------------+-------------+-------------+--------------------+--------------------+--------------------+\n",
      "|RowNumber|CustomerId| Surname|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|SurnameIndex|GeographyIndex|GenderIndex|        Surname_OHE|Geography_OHE|   Gender_OHE|        num_features| scaled_num_features|            features|\n",
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+------------+--------------+-----------+-------------------+-------------+-------------+--------------------+--------------------+--------------------+\n",
      "|        1|  15634602|Hargrave|        619|   France|Female| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|      1958.0|           0.0|        1.0|(2931,[1958],[1.0])|(2,[0],[1.0])|    (1,[],[])|[1.0,1.5634602E7,...|[0.0,0.2756161271...|(2944,[1958,2931,...|\n",
      "|        2|  15647311|    Hill|        608|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|        79.0|           2.0|        1.0|  (2931,[79],[1.0])|    (2,[],[])|    (1,[],[])|[2.0,1.5647311E7,...|[1.00010001000100...|(2944,[79,2934,29...|\n",
      "|        3|  15619304|    Onio|        502|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|       336.0|           0.0|        1.0| (2931,[336],[1.0])|(2,[0],[1.0])|    (1,[],[])|[3.0,1.5619304E7,...|[2.00020002000200...|(2944,[336,2931,2...|\n",
      "|        4|  15701354|    Boni|        699|   France|Female| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|       128.0|           0.0|        1.0| (2931,[128],[1.0])|(2,[0],[1.0])|    (1,[],[])|[4.0,1.5701354E7,...|[3.00030003000300...|(2944,[128,2931,2...|\n",
      "|        5|  15737888|Mitchell|        850|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|        32.0|           2.0|        1.0|  (2931,[32],[1.0])|    (2,[],[])|    (1,[],[])|[5.0,1.5737888E7,...|[4.00040004000400...|(2944,[32,2934,29...|\n",
      "|        6|  15574012|     Chu|        645|    Spain|  Male| 44|     8|113755.78|            2|        1|             0|      149756.71|     1|        14.0|           2.0|        0.0|  (2931,[14],[1.0])|    (2,[],[])|(1,[0],[1.0])|[6.0,1.5574012E7,...|[5.000500050005E-...|(2944,[14,2933,29...|\n",
      "|        7|  15592531|Bartlett|        822|   France|  Male| 50|     7|      0.0|            2|        1|             1|        10062.8|     0|       631.0|           0.0|        0.0| (2931,[631],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|[7.0,1.5592531E7,...|[6.00060006000600...|(2944,[631,2931,2...|\n",
      "|        8|  15656148|  Obinna|        376|  Germany|Female| 29|     4|115046.74|            4|        1|             0|      119346.88|     1|      1269.0|           1.0|        1.0|(2931,[1269],[1.0])|(2,[1],[1.0])|    (1,[],[])|[8.0,1.5656148E7,...|[7.000700070007E-...|(2944,[1269,2932,...|\n",
      "|        9|  15792365|      He|        501|   France|  Male| 44|     4|142051.07|            2|        0|             1|        74940.5|     0|        57.0|           0.0|        0.0|  (2931,[57],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|[9.0,1.5792365E7,...|[8.00080008000800...|(2944,[57,2931,29...|\n",
      "|       10|  15592389|      H?|        684|   France|  Male| 27|     2|134603.88|            1|        1|             1|       71725.73|     0|        44.0|           0.0|        0.0|  (2931,[44],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|[10.0,1.5592389E7...|[9.00090009000900...|(2944,[44,2931,29...|\n",
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+------------+--------------+-----------+-------------------+-------------+-------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now this dataset has the one-hot encoded categorical features and the scaled numerical features\n",
    "dataset.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2b4c912b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RowNumber', 'int'),\n",
       " ('CustomerId', 'int'),\n",
       " ('Surname', 'string'),\n",
       " ('CreditScore', 'int'),\n",
       " ('Geography', 'string'),\n",
       " ('Gender', 'string'),\n",
       " ('Age', 'int'),\n",
       " ('Tenure', 'int'),\n",
       " ('Balance', 'double'),\n",
       " ('NumOfProducts', 'int'),\n",
       " ('HasCrCard', 'int'),\n",
       " ('IsActiveMember', 'int'),\n",
       " ('EstimatedSalary', 'double'),\n",
       " ('Exited', 'int'),\n",
       " ('SurnameIndex', 'double'),\n",
       " ('GeographyIndex', 'double'),\n",
       " ('GenderIndex', 'double'),\n",
       " ('Surname_OHE', 'vector'),\n",
       " ('Geography_OHE', 'vector'),\n",
       " ('Gender_OHE', 'vector'),\n",
       " ('num_features', 'vector'),\n",
       " ('scaled_num_features', 'vector'),\n",
       " ('features', 'vector')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b406750",
   "metadata": {},
   "source": [
    "## Creating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e7bc458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validation and test sets\n",
    "train, validation_test = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "validation, test = validation_test.randomSplit([0.5, 0.5], seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c64e9fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 7033\n",
      "Test Dataset Count: 1466\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fcda7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import *\n",
    "from time import *\n",
    "\n",
    "# instantiate and train naive bayes\n",
    "start = time()\n",
    "\n",
    "nb = NaiveBayes(featuresCol='features', labelCol='Exited')\n",
    "nb_model = nb.fit(train)\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='Exited')\n",
    "lr_model = lr.fit(train)\n",
    "\n",
    "svc = LinearSVC(featuresCol='features', labelCol='Exited')\n",
    "svc_model = svc.fit(train)\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='Exited')\n",
    "rf_model = rf.fit(train)\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='Exited')\n",
    "dt_model = dt.fit(train)\n",
    "\n",
    "gbt = GBTClassifier(featuresCol='features', labelCol='Exited')\n",
    "gbt_model = gbt.fit(train)\n",
    "\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8efb37e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took: 23.695491790771484 seconds\n"
     ]
    }
   ],
   "source": [
    "print (\"Training took:\",end-start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2c3cb777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 score for naive bayes on validation set:0.714324079804785\n",
      "Area under PR for naive bayes on validation set: 0.09860093271152565\n",
      "\n",
      "F1 score for logistic regression on validation set:0.7429544816982064\n",
      "Area under PR for logistic regression on validation set: 0.2882107955382399\n",
      "\n",
      "F1 score for linear svc on validation set:0.7322565865202919\n",
      "Area under PR for linear svc on validation set: 0.27596826415365194\n",
      "\n",
      "F1 score for random forest on validation set:0.714982817564836\n",
      "Area under PR for random forest on validation set: 0.1972018654230513\n",
      "\n",
      "F1 score for decision tree on validation set:0.8346652237983825\n",
      "Area under PR for decision tree on validation set: 0.5304287785966667\n",
      "\n",
      "F1 score for Gradient Boosting on validation set:0.8466321651036282\n",
      "Area under PR for Gradient Boosting on validation set: 0.5795530316500711\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import *\n",
    "# make baseline model predictions\n",
    "# create lists with the models and their respective names\n",
    "models = [nb_model, \n",
    "          lr_model, \n",
    "          svc_model, \n",
    "          rf_model, \n",
    "          dt_model,\n",
    "          gbt_model]\n",
    "\n",
    "model_names = ['naive bayes', \n",
    "               'logistic regression', \n",
    "               'linear svc', \n",
    "               'random forest', \n",
    "               'decision tree',\n",
    "                'Gradient Boosting']\n",
    "\n",
    "# for all models, make prediction, calculate f1 and area under the PR scores and display results\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    model_name = model_names[i]\n",
    "    \n",
    "    # predict on validation set\n",
    "    validation_prediction = model.transform(validation)\n",
    " \n",
    "    # use MulticlassClassificationEvaluator to get f1 scores\n",
    "    evaluator1 = MulticlassClassificationEvaluator(labelCol='Exited')\n",
    " \n",
    "    # use BinaryClassificationEvaluator to get area under PR \n",
    "    evaluator2 = BinaryClassificationEvaluator(\n",
    "                 rawPredictionCol='prediction', labelCol='Exited')\n",
    "    # make evaluation and print f1 and area under PR score per model\n",
    "    print('')\n",
    "    print('F1 score for {} on validation set:{}'.format(\\\n",
    "          (model_name), \\\n",
    "          (evaluator1.evaluate(validation_prediction, {evaluator1.metricName:'f1'}))))\n",
    " \n",
    "    print('Area under PR for {} on validation set: {}'.format((model_name), \\\n",
    "          (evaluator2.evaluate(validation_prediction,{evaluator2.metricName:'areaUnderPR'}))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "279dbf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time for hyperparameter tuning on GBT model: 89.19464778900146 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# fit cv model and train it\n",
    "start = time()\n",
    "\n",
    "paramGrid_gbt = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth,[5, 10]) \\\n",
    "    .addGrid(gbt.maxIter,[5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=paramGrid_gbt,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol='Exited',\\\n",
    "                          metricName='f1'),\n",
    "                          numFolds=3)\n",
    "\n",
    "# fit cv model and train it\n",
    "start = time()\n",
    "cvModel_gbt  = crossval.fit(train)\n",
    "end = time()\n",
    "print('Total training time for hyperparameter tuning on GBT model: {} seconds'\\\n",
    "      .format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0aeee232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Prediction Metrics:\n",
      "F-1 Score:0.8371176844934723\n",
      "Accuracy: 0.8485675306957708\n",
      "\n",
      "Validation Set Prediction Metrics:\n",
      "F-1 Score:0.8419843752867925\n",
      "Accuracy: 0.854763491005996\n"
     ]
    }
   ],
   "source": [
    "# predict on testy set\n",
    "results_final = cvModel_gbt.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol='Exited')\n",
    "print('Test Set Prediction Metrics:')\n",
    "print('F-1 Score:{}'.format(evaluator.evaluate(results_final, {evaluator.metricName: \"f1\"})))\n",
    "print('Accuracy: {}'.format(evaluator.evaluate(results_final, {evaluator.metricName: \"accuracy\"})))\n",
    "print('')\n",
    "\n",
    "# predict on validation set\n",
    "results_final = cvModel_gbt.transform(validation)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol='Exited')\n",
    "print('Validation Set Prediction Metrics:')\n",
    "print('F-1 Score:{}'.format(evaluator.evaluate(results_final, {evaluator.metricName: \"f1\"})))\n",
    "print('Accuracy: {}'.format(evaluator.evaluate(results_final, {evaluator.metricName: \"accuracy\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b8935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
